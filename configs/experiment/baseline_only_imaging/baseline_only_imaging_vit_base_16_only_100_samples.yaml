# @package _global_

defaults:
  - override /data: downstream
  - override /model: only_imaging
  - override /callbacks: default
  - override /trainer: default

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["vit_base_16", "only_imaging", "try_with_only_n_samples", "baseline"]

trainer:
  max_epochs: 100
  gradient_clip_val: 1.0

data:
  try_with_only_n_samples: 100
  batch_size: 128

model:
  optimizer:
    lr: 1e-3

  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: true
    T_max: ${trainer.max_epochs}
    eta_min: 1e-6


logger:
  wandb:
    tags: ${tags}
    group: "setup"